#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch_geometric
from torch_geometric.nn import GCNConv, GATConv
import numpy as np
from typing import Dict, List, Tuple, Optional
import networkx as nx
from collections import deque
import random
import math
from constraint_manager import ConstraintManager

class GraphEncoder(nn.Module):
    """å›¾ç¥ç»ç½‘ç»œç¼–ç å™¨ï¼Œç”¨äºç¼–ç ç‰©ç†èŠ‚ç‚¹å’Œè™šæ‹Ÿå·¥ä½œèŠ‚ç‚¹"""
    
    def __init__(self, node_features: int, hidden_dim: int = 128, num_layers: int = 3):
        super(GraphEncoder, self).__init__()
        self.hidden_dim = hidden_dim
        
        # å›¾å·ç§¯å±‚
        self.conv_layers = nn.ModuleList()
        self.conv_layers.append(GATConv(node_features, hidden_dim, heads=8, concat=False))
        
        for _ in range(num_layers - 1):
            self.conv_layers.append(GATConv(hidden_dim, hidden_dim, heads=8, concat=False))
        
        # è¾“å‡ºæŠ•å½±å±‚
        self.output_proj = nn.Linear(hidden_dim, hidden_dim)
        
    def forward(self, x, edge_index, edge_attr=None):
        """
        Args:
            x: èŠ‚ç‚¹ç‰¹å¾ [num_nodes, node_features]
            edge_index: è¾¹ç´¢å¼• [2, num_edges]
            edge_attr: è¾¹ç‰¹å¾ [num_edges, edge_features]
        """
        h = x
        
        for conv in self.conv_layers:
            h = conv(h, edge_index, edge_attr)
            h = F.relu(h)
            h = F.dropout(h, p=0.1, training=self.training)
        
        return self.output_proj(h)

class MappingActor(nn.Module):
    """æ˜ å°„Actorï¼Œè´Ÿè´£è¾“å‡ºæ‰€æœ‰è™šæ‹Ÿä»»åŠ¡èŠ‚ç‚¹çš„æ˜ å°„ç»“æœ"""
    
    def __init__(self, 
                 physical_node_dim: int,
                 virtual_node_dim: int,
                 hidden_dim: int = 128,
                 num_physical_nodes: int = 10,
                 max_virtual_nodes: int = 8):
        super(MappingActor, self).__init__()
        
        self.num_physical_nodes = num_physical_nodes
        self.max_virtual_nodes = max_virtual_nodes
        self.hidden_dim = hidden_dim
        
        # å›¾ç¼–ç å™¨
        self.physical_encoder = GraphEncoder(physical_node_dim, hidden_dim)
        self.virtual_encoder = GraphEncoder(virtual_node_dim, hidden_dim)
        
        # æ³¨æ„åŠ›æœºåˆ¶ï¼Œç”¨äºè®¡ç®—ç‰©ç†èŠ‚ç‚¹å’Œè™šæ‹ŸèŠ‚ç‚¹çš„åŒ¹é…åº¦
        self.attention = nn.MultiheadAttention(hidden_dim, num_heads=8, batch_first=True)
        
        # å…¨å±€æ˜ å°„ç­–ç•¥ç½‘ç»œ - è¾“å‡ºæ‰€æœ‰è™šæ‹ŸèŠ‚ç‚¹çš„æ˜ å°„
        self.global_mapping_head = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim * 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, num_physical_nodes)  # æ¯ä¸ªè™šæ‹ŸèŠ‚ç‚¹è¾“å‡ºä¸€ä¸ªç‰©ç†èŠ‚ç‚¹é€‰æ‹©
        )
        
        # æ˜ å°„çº¦æŸæ£€æŸ¥å±‚
        self.constraint_checker = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, 1),
            nn.Sigmoid()
        )
        
    def forward(self, 
                physical_features, physical_edge_index, physical_edge_attr,
                virtual_features, virtual_edge_index, virtual_edge_attr):
        """
        Args:
            physical_features: ç‰©ç†èŠ‚ç‚¹ç‰¹å¾ [num_physical_nodes, physical_node_dim]
            physical_edge_index: ç‰©ç†ç½‘ç»œè¾¹ç´¢å¼• [2, num_physical_edges]
            physical_edge_attr: ç‰©ç†ç½‘ç»œè¾¹ç‰¹å¾ [num_physical_edges, edge_features]
            virtual_features: è™šæ‹ŸèŠ‚ç‚¹ç‰¹å¾ [num_virtual_nodes, virtual_node_dim]
            virtual_edge_index: è™šæ‹Ÿç½‘ç»œè¾¹ç´¢å¼• [2, num_virtual_edges]
            virtual_edge_attr: è™šæ‹Ÿç½‘ç»œè¾¹ç‰¹å¾ [num_virtual_edges, edge_features]
        
        Returns:
            mapping_logits: æ‰€æœ‰è™šæ‹ŸèŠ‚ç‚¹çš„æ˜ å°„logits [num_virtual_nodes, num_physical_nodes]
            constraint_scores: çº¦æŸæ»¡è¶³åº¦åˆ†æ•° [num_virtual_nodes, num_physical_nodes]
        """
        # ç¼–ç ç‰©ç†ç½‘ç»œå’Œè™šæ‹Ÿç½‘ç»œ
        physical_encoded = self.physical_encoder(physical_features, physical_edge_index, physical_edge_attr)
        virtual_encoded = self.virtual_encoder(virtual_features, virtual_edge_index, virtual_edge_attr)
        
        # æ³¨æ„åŠ›æœºåˆ¶ï¼šè®¡ç®—è™šæ‹ŸèŠ‚ç‚¹å¯¹ç‰©ç†èŠ‚ç‚¹çš„æ³¨æ„åŠ›
        # [num_virtual_nodes, hidden_dim] -> [1, num_virtual_nodes, hidden_dim]
        virtual_encoded_expanded = virtual_encoded.unsqueeze(0)
        physical_encoded_expanded = physical_encoded.unsqueeze(0)
        
        # è®¡ç®—æ³¨æ„åŠ›
        attended_virtual, attention_weights = self.attention(
            virtual_encoded_expanded, 
            physical_encoded_expanded, 
            physical_encoded_expanded
        )
        attended_virtual = attended_virtual.squeeze(0)  # [num_virtual_nodes, hidden_dim]
        
        # åˆå¹¶ç¼–ç ç‰¹å¾
        combined_features = torch.cat([attended_virtual, virtual_encoded], dim=1)
        
        # è·å–å®é™…çš„è™šæ‹ŸèŠ‚ç‚¹æ•°é‡
        actual_virtual_nodes = virtual_features.size(0)
        
        # å…¨å±€æ˜ å°„ç­–ç•¥ï¼šä¸ºæ¯ä¸ªè™šæ‹ŸèŠ‚ç‚¹è¾“å‡ºæ˜ å°„logits
        mapping_logits = self.global_mapping_head(combined_features)  # [actual_virtual_nodes, num_physical_nodes]
        
        # çº¦æŸæ£€æŸ¥ï¼šè®¡ç®—æ¯ä¸ªè™šæ‹ŸèŠ‚ç‚¹çš„çº¦æŸæ»¡è¶³åº¦
        constraint_scores = self.constraint_checker(combined_features)
        # ä¸ºæ¯ä¸ªè™šæ‹ŸèŠ‚ç‚¹å¯¹æ¯ä¸ªç‰©ç†èŠ‚ç‚¹è®¡ç®—çº¦æŸåˆ†æ•°
        constraint_scores = constraint_scores.squeeze(-1).unsqueeze(1).expand(-1, self.num_physical_nodes)
        
        return mapping_logits, constraint_scores, attention_weights

class BandwidthActor(nn.Module):
    """å¸¦å®½Actorï¼Œè´Ÿè´£è¾“å‡ºæ‰€æœ‰è™šæ‹Ÿé“¾è·¯çš„å¸¦å®½åˆ†é…ç»“æœ"""
    
    def __init__(self, 
                 physical_node_dim: int,
                 virtual_node_dim: int,
                 hidden_dim: int = 128,
                 bandwidth_levels: int = 10,
                 max_virtual_nodes: int = 8):
        super(BandwidthActor, self).__init__()
        
        self.bandwidth_levels = bandwidth_levels
        self.max_virtual_nodes = max_virtual_nodes
        self.hidden_dim = hidden_dim
        
        # å›¾ç¼–ç å™¨
        self.physical_encoder = GraphEncoder(physical_node_dim, hidden_dim)
        self.virtual_encoder = GraphEncoder(virtual_node_dim, hidden_dim)
        
        # é“¾è·¯ç¼–ç å™¨ï¼šä¸“é—¨å¤„ç†è™šæ‹Ÿé“¾è·¯ä¿¡æ¯
        self.link_encoder = nn.Sequential(
            nn.Linear(virtual_node_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim)
        )
        
        # æ³¨æ„åŠ›æœºåˆ¶
        self.attention = nn.MultiheadAttention(hidden_dim, num_heads=8, batch_first=True)
        
        # å…¨å±€å¸¦å®½åˆ†é…ç­–ç•¥ç½‘ç»œ
        self.global_bandwidth_head = nn.Sequential(
            nn.Linear(hidden_dim * 3, hidden_dim * 2),  # ç‰©ç† + è™šæ‹Ÿ + é“¾è·¯ç‰¹å¾
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, bandwidth_levels)  # æ¯ä¸ªé“¾è·¯è¾“å‡ºä¸€ä¸ªå¸¦å®½ç­‰çº§é€‰æ‹©
        )
        
        # å¸¦å®½çº¦æŸæ£€æŸ¥å±‚
        self.bandwidth_constraint_checker = nn.Sequential(
            nn.Linear(hidden_dim * 3, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, 1),
            nn.Sigmoid()
        )
        
    def forward(self, 
                physical_features, physical_edge_index, physical_edge_attr,
                virtual_features, virtual_edge_index, virtual_edge_attr,
                mapping_result):
        """
        Args:
            physical_features: ç‰©ç†èŠ‚ç‚¹ç‰¹å¾
            physical_edge_index: ç‰©ç†ç½‘ç»œè¾¹ç´¢å¼•
            physical_edge_attr: ç‰©ç†ç½‘ç»œè¾¹ç‰¹å¾
            virtual_features: è™šæ‹ŸèŠ‚ç‚¹ç‰¹å¾
            virtual_edge_index: è™šæ‹Ÿç½‘ç»œè¾¹ç´¢å¼•
            virtual_edge_attr: è™šæ‹Ÿç½‘ç»œè¾¹ç‰¹å¾
            mapping_result: æ˜ å°„ç»“æœ [num_virtual_nodes] (ç‰©ç†èŠ‚ç‚¹ç´¢å¼•)
        
        Returns:
            bandwidth_logits: æ‰€æœ‰è™šæ‹Ÿé“¾è·¯çš„å¸¦å®½logits [num_links, bandwidth_levels]
            constraint_scores: å¸¦å®½çº¦æŸæ»¡è¶³åº¦åˆ†æ•° [num_links, bandwidth_levels]
        """
        # ç¼–ç ç‰©ç†ç½‘ç»œå’Œè™šæ‹Ÿç½‘ç»œ
        physical_encoded = self.physical_encoder(physical_features, physical_edge_index, physical_edge_attr)
        virtual_encoded = self.virtual_encoder(virtual_features, virtual_edge_index, virtual_edge_attr)
        
        # æ„å»ºè™šæ‹Ÿé“¾è·¯ç‰¹å¾
        num_virtual_nodes = virtual_features.size(0)
        link_features = []
        link_indices = []
        
        for i in range(num_virtual_nodes):
            for j in range(i + 1, num_virtual_nodes):
                # åˆå¹¶ä¸¤ä¸ªè™šæ‹ŸèŠ‚ç‚¹çš„ç‰¹å¾
                link_feature = torch.cat([virtual_features[i], virtual_features[j]], dim=0)
                link_features.append(link_feature)
                link_indices.append([i, j])
        
        if link_features:
            link_features = torch.stack(link_features)  # [num_links, virtual_node_dim * 2]
            link_encoded = self.link_encoder(link_features)  # [num_links, hidden_dim]
        else:
            link_encoded = torch.empty(0, self.hidden_dim, device=virtual_features.device)
        
        # æ³¨æ„åŠ›æœºåˆ¶ï¼šè€ƒè™‘æ˜ å°„ç»“æœçš„å½±å“
        if link_encoded.size(0) > 0:
            # æ ¹æ®æ˜ å°„ç»“æœè°ƒæ•´æ³¨æ„åŠ›
            mapped_physical_features = physical_encoded[mapping_result]  # [num_virtual_nodes, hidden_dim]
            
            # è®¡ç®—é“¾è·¯å¯¹ç‰©ç†è·¯å¾„çš„æ³¨æ„åŠ›
            link_encoded_expanded = link_encoded.unsqueeze(0)
            mapped_physical_expanded = mapped_physical_features.unsqueeze(0)
            
            attended_links, link_attention_weights = self.attention(
                link_encoded_expanded,
                mapped_physical_expanded,
                mapped_physical_expanded
            )
            attended_links = attended_links.squeeze(0)  # [num_links, hidden_dim]
            
            # åˆå¹¶æ‰€æœ‰ç‰¹å¾
            combined_features = torch.cat([
                attended_links,  # é“¾è·¯ç‰¹å¾
                virtual_encoded.mean(dim=0).expand(link_encoded.size(0), -1),  # å…¨å±€è™šæ‹Ÿç‰¹å¾
                physical_encoded.mean(dim=0).expand(link_encoded.size(0), -1)   # å…¨å±€ç‰©ç†ç‰¹å¾
            ], dim=1)
            
            # å…¨å±€å¸¦å®½åˆ†é…ç­–ç•¥
            bandwidth_logits = self.global_bandwidth_head(combined_features)  # [num_links, bandwidth_levels]
            
            # å¸¦å®½çº¦æŸæ£€æŸ¥
            constraint_scores = self.bandwidth_constraint_checker(combined_features)
            constraint_scores = constraint_scores.expand(-1, self.bandwidth_levels)
            
        else:
            bandwidth_logits = torch.empty(0, self.bandwidth_levels, device=virtual_features.device)
            constraint_scores = torch.empty(0, self.bandwidth_levels, device=virtual_features.device)
            link_attention_weights = None
        
        return bandwidth_logits, constraint_scores, link_attention_weights, link_indices

class Critic(nn.Module):
    """Criticç½‘ç»œï¼Œè¯„ä¼°çŠ¶æ€ä»·å€¼"""
    
    def __init__(self, 
                 physical_node_dim: int,
                 virtual_node_dim: int,
                 hidden_dim: int = 128):
        super(Critic, self).__init__()
        
        # å›¾ç¼–ç å™¨
        self.physical_encoder = GraphEncoder(physical_node_dim, hidden_dim)
        self.virtual_encoder = GraphEncoder(virtual_node_dim, hidden_dim)
        
        # å…¨å±€ä»·å€¼è¯„ä¼°ç½‘ç»œ
        self.value_head = nn.Sequential(
            nn.Linear(hidden_dim * 2, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Linear(hidden_dim // 2, 1)
        )
        
    def forward(self, 
                physical_features, physical_edge_index, physical_edge_attr,
                virtual_features, virtual_edge_index, virtual_edge_attr):
        """
        Args:
            physical_features: ç‰©ç†èŠ‚ç‚¹ç‰¹å¾
            physical_edge_index: ç‰©ç†ç½‘ç»œè¾¹ç´¢å¼•
            physical_edge_attr: ç‰©ç†ç½‘ç»œè¾¹ç‰¹å¾
            virtual_features: è™šæ‹ŸèŠ‚ç‚¹ç‰¹å¾
            virtual_edge_index: è™šæ‹Ÿç½‘ç»œè¾¹ç´¢å¼•
            virtual_edge_attr: è™šæ‹Ÿç½‘ç»œè¾¹ç‰¹å¾
        """
        # ç¼–ç ç‰©ç†ç½‘ç»œå’Œè™šæ‹Ÿç½‘ç»œ
        physical_encoded = self.physical_encoder(physical_features, physical_edge_index, physical_edge_attr)
        virtual_encoded = self.virtual_encoder(virtual_features, virtual_edge_index, virtual_edge_attr)
        
        # å…¨å±€ç‰¹å¾èšåˆ
        global_physical = torch.mean(physical_encoded, dim=0)  # [hidden_dim]
        global_virtual = torch.mean(virtual_encoded, dim=0)    # [hidden_dim]
        
        # åˆå¹¶ç‰¹å¾
        combined_features = torch.cat([global_physical, global_virtual], dim=0)
        
        # ä»·å€¼è¯„ä¼°
        value = self.value_head(combined_features)
        
        return value

class TwoStagePPOAgent:
    """ä¸¤é˜¶æ®µPPOæ™ºèƒ½ä½“ï¼Œä½¿ç”¨ä¸¤ä¸ªç‹¬ç«‹çš„Actor"""
    
    def __init__(self, 
                 physical_node_dim: int,
                 virtual_node_dim: int,
                 num_physical_nodes: int,
                 max_virtual_nodes: int,
                 bandwidth_levels: int,
                 lr: float = 3e-4,
                 gamma: float = 0.99,
                 gae_lambda: float = 0.95,
                 clip_ratio: float = 0.2,
                 value_loss_coef: float = 0.5,
                 entropy_coef: float = 0.01):
        
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # ç½‘ç»œå‚æ•°
        self.num_physical_nodes = num_physical_nodes
        self.max_virtual_nodes = max_virtual_nodes
        self.bandwidth_levels = bandwidth_levels
        
        # åˆ›å»ºç½‘ç»œ
        self.mapping_actor = MappingActor(
            physical_node_dim, virtual_node_dim, 
            num_physical_nodes=num_physical_nodes,
            max_virtual_nodes=max_virtual_nodes
        ).to(self.device)
        
        self.bandwidth_actor = BandwidthActor(
            physical_node_dim, virtual_node_dim,
            bandwidth_levels=bandwidth_levels,
            max_virtual_nodes=max_virtual_nodes
        ).to(self.device)
        
        self.critic = Critic(physical_node_dim, virtual_node_dim).to(self.device)
        
        # ä¼˜åŒ–å™¨
        self.mapping_optimizer = torch.optim.Adam(self.mapping_actor.parameters(), lr=lr)
        self.bandwidth_optimizer = torch.optim.Adam(self.bandwidth_actor.parameters(), lr=lr)
        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=lr)
        
        # PPOå‚æ•°
        self.gamma = gamma
        self.gae_lambda = gae_lambda
        self.clip_ratio = clip_ratio
        self.value_loss_coef = value_loss_coef
        self.entropy_coef = entropy_coef
        
        # çº¦æŸç®¡ç†å™¨
        self.constraint_manager = ConstraintManager(bandwidth_levels=bandwidth_levels)
        
        # ç»éªŒç¼“å†²åŒº
        self.states = []
        self.mapping_actions = []
        self.bandwidth_actions = []
        self.rewards = []
        self.values = []
        self.mapping_log_probs = []
        self.bandwidth_log_probs = []
        self.dones = []
    
    def select_actions(self, state):
        """
        é€‰æ‹©æ˜ å°„å’Œå¸¦å®½åˆ†é…åŠ¨ä½œ
        
        Args:
            state: ç¯å¢ƒçŠ¶æ€å­—å…¸
        
        Returns:
            mapping_action: æ˜ å°„åŠ¨ä½œ [num_virtual_nodes]
            bandwidth_action: å¸¦å®½åŠ¨ä½œ [num_links]
            mapping_log_prob: æ˜ å°„åŠ¨ä½œçš„logæ¦‚ç‡
            bandwidth_log_prob: å¸¦å®½åŠ¨ä½œçš„logæ¦‚ç‡
            value: çŠ¶æ€ä»·å€¼
        """
        # æå–çŠ¶æ€ä¿¡æ¯
        physical_features = state['physical_features'].to(self.device)
        physical_edge_index = state['physical_edge_index'].to(self.device)
        physical_edge_attr = state['physical_edge_attr'].to(self.device)
        virtual_features = state['virtual_features'].to(self.device)
        virtual_edge_index = state['virtual_edge_index'].to(self.device)
        virtual_edge_attr = state['virtual_edge_attr'].to(self.device)
        
        # ç”ŸæˆèŠ‚ç‚¹æ˜ å°„çº¦æŸ
        node_constraints = self.constraint_manager.generate_node_mapping_constraints(
            physical_features, virtual_features, physical_edge_index, virtual_edge_index
        )
        
        # ç¬¬ä¸€é˜¶æ®µï¼šæ˜ å°„Actor
        mapping_logits, constraint_scores, _ = self.mapping_actor(
            physical_features, physical_edge_index, physical_edge_attr,
            virtual_features, virtual_edge_index, virtual_edge_attr
        )
        
        # åº”ç”¨çº¦æŸç®¡ç†å™¨ç”Ÿæˆçš„çº¦æŸ
        mapping_logits = self.constraint_manager.apply_node_mapping_constraints(
            mapping_logits, node_constraints, temperature=1.0
        )
        
        # åº”ç”¨åŸæœ‰çš„çº¦æŸåˆ†æ•°ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        mapping_logits = mapping_logits + torch.log(constraint_scores + 1e-8)
        
        # æ£€æŸ¥æ•°å€¼ç¨³å®šæ€§
        if torch.isnan(mapping_logits).any() or torch.isinf(mapping_logits).any():
            print("è­¦å‘Šï¼šmapping_logits åŒ…å« NaN æˆ– Inf å€¼ï¼Œä½¿ç”¨å‡åŒ€åˆ†å¸ƒ")
            # ä¿æŒæ¢¯åº¦ä¿¡æ¯ï¼Œåªæ›¿æ¢æ— æ•ˆå€¼
            mapping_logits = torch.where(torch.isnan(mapping_logits) | torch.isinf(mapping_logits), 
                                       torch.zeros_like(mapping_logits), mapping_logits)
        
        mapping_probs = F.softmax(mapping_logits, dim=-1)
        
        # é‡‡æ ·æ˜ å°„åŠ¨ä½œ
        mapping_dist = torch.distributions.Categorical(mapping_probs)
        mapping_action = mapping_dist.sample()
        mapping_log_prob = mapping_dist.log_prob(mapping_action)
        
        # ç¬¬äºŒé˜¶æ®µï¼šå¸¦å®½Actor
        bandwidth_logits, bandwidth_constraint_scores, _, link_indices = self.bandwidth_actor(
            physical_features, physical_edge_index, physical_edge_attr,
            virtual_features, virtual_edge_index, virtual_edge_attr,
            mapping_action
        )
        
        if bandwidth_logits.size(0) > 0:
            # ç”Ÿæˆå¸¦å®½çº¦æŸ
            # ä»ç¯å¢ƒçŠ¶æ€ä¸­è·å–bandwidth_mapping
            bandwidth_mapping = state.get('bandwidth_mapping', {i: 10 + i * 20 for i in range(self.bandwidth_levels)})
            # ä¼ é€’æœŸæœ›çš„é“¾è·¯æ•°é‡ä»¥åŒ¹é…bandwidth_logitsçš„å½¢çŠ¶
            expected_num_links = bandwidth_logits.size(0)
            bandwidth_constraints = self.constraint_manager.generate_bandwidth_constraints(
                virtual_edge_attr, bandwidth_mapping, expected_num_links
            )
            
            # åº”ç”¨çº¦æŸç®¡ç†å™¨ç”Ÿæˆçš„å¸¦å®½çº¦æŸ
            bandwidth_logits = self.constraint_manager.apply_bandwidth_constraints(
                bandwidth_logits, bandwidth_constraints, temperature=1.0
            )
            
            # åº”ç”¨åŸæœ‰çš„å¸¦å®½çº¦æŸåˆ†æ•°ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            bandwidth_logits = bandwidth_logits + torch.log(bandwidth_constraint_scores + 1e-8)
            
            # æ£€æŸ¥æ•°å€¼ç¨³å®šæ€§
            if torch.isnan(bandwidth_logits).any() or torch.isinf(bandwidth_logits).any():
                print("è­¦å‘Šï¼šbandwidth_logits åŒ…å« NaN æˆ– Inf å€¼ï¼Œä½¿ç”¨å‡åŒ€åˆ†å¸ƒ")
                # ä¿æŒæ¢¯åº¦ä¿¡æ¯ï¼Œåªæ›¿æ¢æ— æ•ˆå€¼
                bandwidth_logits = torch.where(torch.isnan(bandwidth_logits) | torch.isinf(bandwidth_logits), 
                                             torch.zeros_like(bandwidth_logits), bandwidth_logits)
            
            bandwidth_probs = F.softmax(bandwidth_logits, dim=-1)
            
            # é‡‡æ ·å¸¦å®½åŠ¨ä½œ
            bandwidth_dist = torch.distributions.Categorical(bandwidth_probs)
            bandwidth_action = bandwidth_dist.sample()
            bandwidth_log_prob = bandwidth_dist.log_prob(bandwidth_action)
        else:
            bandwidth_action = torch.empty(0, dtype=torch.long, device=self.device)
            bandwidth_log_prob = torch.empty(0, dtype=torch.float, device=self.device)
        
        # Criticè¯„ä¼°
        value = self.critic(
            physical_features, physical_edge_index, physical_edge_attr,
            virtual_features, virtual_edge_index, virtual_edge_attr
        )
        
        return (mapping_action.cpu().detach().numpy(), bandwidth_action.cpu().detach().numpy(),
                mapping_log_prob.cpu().detach().numpy(), bandwidth_log_prob.cpu().detach().numpy(),
                value.cpu().item(), link_indices)
    
    def store_transition(self, state, mapping_action, bandwidth_action, 
                        reward, value, mapping_log_prob, bandwidth_log_prob, done):
        """å­˜å‚¨ç»éªŒ"""
        self.states.append(state)
        self.mapping_actions.append(mapping_action)
        self.bandwidth_actions.append(bandwidth_action)
        self.rewards.append(reward)
        self.values.append(value)
        self.mapping_log_probs.append(mapping_log_prob)
        self.bandwidth_log_probs.append(bandwidth_log_prob)
        self.dones.append(done)
    
    def update(self):
        """æ›´æ–°ç½‘ç»œ"""
        if len(self.states) < 2:
            return
        
        # è®¡ç®—ä¼˜åŠ¿å‡½æ•°
        advantages = self._compute_advantages()
        
        # è½¬æ¢ä¸ºtensor
        states = self.states
        # å¤„ç†ä¸åŒé•¿åº¦çš„mapping_actions
        mapping_actions = []
        for actions in self.mapping_actions:
            if isinstance(actions, np.ndarray):
                mapping_actions.append(torch.tensor(actions, dtype=torch.long, device=self.device))
            else:
                mapping_actions.append(torch.tensor(np.array(actions), dtype=torch.long, device=self.device))
        
        bandwidth_actions = [torch.tensor(actions, dtype=torch.long, device=self.device) for actions in self.bandwidth_actions]
        old_mapping_log_probs = [torch.tensor(probs, dtype=torch.float32, device=self.device) for probs in self.mapping_log_probs]
        old_bandwidth_log_probs = [torch.tensor(probs, dtype=torch.float32, device=self.device) for probs in self.bandwidth_log_probs]
        returns = advantages + torch.tensor(self.values, dtype=torch.float32, device=self.device)
        
        # æ›´æ–°æ˜ å°„Actor
        self._update_mapping_actor(states, mapping_actions, old_mapping_log_probs, advantages, returns)
        
        # æ›´æ–°å¸¦å®½Actor
        self._update_bandwidth_actor(states, bandwidth_actions, old_bandwidth_log_probs, advantages, returns)
        
        # æ›´æ–°Critic
        self._update_critic(states, returns)
        
        # æ¸…ç©ºç¼“å†²åŒº
        self.states.clear()
        self.mapping_actions.clear()
        self.bandwidth_actions.clear()
        self.rewards.clear()
        self.values.clear()
        self.mapping_log_probs.clear()
        self.bandwidth_log_probs.clear()
        self.dones.clear()
    
    def _update_mapping_actor(self, states, mapping_actions, old_log_probs, advantages, returns):
        """æ›´æ–°æ˜ å°„Actor"""
        # é‡æ–°è®¡ç®—å½“å‰ç­–ç•¥çš„æ¦‚ç‡
        current_log_probs = []
        entropies = []
        
        for i, state in enumerate(states):
            physical_features = state['physical_features'].to(self.device)
            physical_edge_index = state['physical_edge_index'].to(self.device)
            physical_edge_attr = state['physical_edge_attr'].to(self.device)
            virtual_features = state['virtual_features'].to(self.device)
            virtual_edge_index = state['virtual_edge_index'].to(self.device)
            virtual_edge_attr = state['virtual_edge_attr'].to(self.device)
            
            # ç”ŸæˆèŠ‚ç‚¹æ˜ å°„çº¦æŸ
            node_constraints = self.constraint_manager.generate_node_mapping_constraints(
                physical_features, virtual_features, physical_edge_index, virtual_edge_index
            )
            
            mapping_logits, constraint_scores, _ = self.mapping_actor(
                physical_features, physical_edge_index, physical_edge_attr,
                virtual_features, virtual_edge_index, virtual_edge_attr
            )
            
            # åº”ç”¨çº¦æŸç®¡ç†å™¨ç”Ÿæˆçš„çº¦æŸ
            mapping_logits = self.constraint_manager.apply_node_mapping_constraints(
                mapping_logits, node_constraints, temperature=1.0
            )
            
            # åº”ç”¨åŸæœ‰çš„çº¦æŸåˆ†æ•°ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            mapping_logits = mapping_logits + torch.log(constraint_scores + 1e-8)
            
            # æ£€æŸ¥æ•°å€¼ç¨³å®šæ€§
            if torch.isnan(mapping_logits).any() or torch.isinf(mapping_logits).any():
                print("è­¦å‘Šï¼šæ›´æ–°é˜¶æ®µ mapping_logits åŒ…å« NaN æˆ– Inf å€¼ï¼Œä½¿ç”¨å‡åŒ€åˆ†å¸ƒ")
                # ä¿æŒæ¢¯åº¦ä¿¡æ¯ï¼Œåªæ›¿æ¢æ— æ•ˆå€¼
                mapping_logits = torch.where(torch.isnan(mapping_logits) | torch.isinf(mapping_logits), 
                                           torch.zeros_like(mapping_logits), mapping_logits)
            
            mapping_probs = F.softmax(mapping_logits, dim=-1)
            
            mapping_dist = torch.distributions.Categorical(mapping_probs)
            current_log_prob = mapping_dist.log_prob(mapping_actions[i])
            entropy = mapping_dist.entropy().mean()
            
            current_log_probs.append(current_log_prob)
            entropies.append(entropy)
        
        if current_log_probs:
            # å¤„ç†ä¸åŒé•¿åº¦çš„logæ¦‚ç‡
            all_current_log_probs = []
            all_old_log_probs = []
            all_advantages = []
            all_entropies = []
            
            for i, (current_log_prob, old_log_prob, entropy) in enumerate(zip(current_log_probs, old_log_probs, entropies)):
                all_current_log_probs.append(current_log_prob)
                all_old_log_probs.append(old_log_prob)
                all_entropies.append(entropy)
                # ä¸ºæ¯ä¸ªè™šæ‹ŸèŠ‚ç‚¹åˆ†é…ç›¸åŒçš„ä¼˜åŠ¿å€¼
                all_advantages.extend([advantages[i]] * len(current_log_prob))
            
            # è¿æ¥æ‰€æœ‰logæ¦‚ç‡
            current_log_probs = torch.cat(all_current_log_probs)
            old_log_probs = torch.cat(all_old_log_probs)
            all_advantages = torch.tensor(all_advantages, device=self.device)
            entropies = torch.stack(all_entropies)
            
            # è®¡ç®—æ¯”ç‡
            ratio = torch.exp(current_log_probs - old_log_probs)
            
            # PPOæŸå¤±
            surr1 = ratio * all_advantages
            surr2 = torch.clamp(ratio, 1 - self.clip_ratio, 1 + self.clip_ratio) * all_advantages
            mapping_loss = -torch.min(surr1, surr2).mean()
            
            # ç†µæŸå¤±
            entropy_loss = -entropies.mean()
            
            # æ€»æŸå¤±
            total_loss = mapping_loss + self.entropy_coef * entropy_loss
            
            # æ›´æ–°
            self.mapping_optimizer.zero_grad()
            total_loss.backward()
            self.mapping_optimizer.step()
    
    def _update_bandwidth_actor(self, states, bandwidth_actions, old_log_probs, advantages, returns):
        """æ›´æ–°å¸¦å®½Actor"""
        # é‡æ–°è®¡ç®—å½“å‰ç­–ç•¥çš„æ¦‚ç‡
        current_log_probs = []
        entropies = []
        
        for i, state in enumerate(states):
            physical_features = state['physical_features'].to(self.device)
            physical_edge_index = state['physical_edge_index'].to(self.device)
            physical_edge_attr = state['physical_edge_attr'].to(self.device)
            virtual_features = state['virtual_features'].to(self.device)
            virtual_edge_index = state['virtual_edge_index'].to(self.device)
            virtual_edge_attr = state['virtual_edge_attr'].to(self.device)
            
            # éœ€è¦æ˜ å°„ç»“æœï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
            mapping_action = torch.randint(0, self.num_physical_nodes, (self.max_virtual_nodes,), device=self.device)
            
            bandwidth_logits, bandwidth_constraint_scores, _, _ = self.bandwidth_actor(
                physical_features, physical_edge_index, physical_edge_attr,
                virtual_features, virtual_edge_index, virtual_edge_attr,
                mapping_action
            )
            
            if bandwidth_logits.size(0) > 0:
                # ç”Ÿæˆå¸¦å®½çº¦æŸ
                bandwidth_mapping = state.get('bandwidth_mapping', {i: 10 + i * 20 for i in range(self.bandwidth_levels)})
                expected_num_links = bandwidth_logits.size(0)
                bandwidth_constraints = self.constraint_manager.generate_bandwidth_constraints(
                    virtual_edge_attr, bandwidth_mapping, expected_num_links
                )
                
                # åº”ç”¨çº¦æŸç®¡ç†å™¨ç”Ÿæˆçš„å¸¦å®½çº¦æŸ
                bandwidth_logits = self.constraint_manager.apply_bandwidth_constraints(
                    bandwidth_logits, bandwidth_constraints, temperature=1.0
                )
                
                # åº”ç”¨åŸæœ‰çš„å¸¦å®½çº¦æŸåˆ†æ•°ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                bandwidth_logits = bandwidth_logits + torch.log(bandwidth_constraint_scores + 1e-8)
                
                # æ£€æŸ¥æ•°å€¼ç¨³å®šæ€§
                if torch.isnan(bandwidth_logits).any() or torch.isinf(bandwidth_logits).any():
                    print("è­¦å‘Šï¼šæ›´æ–°é˜¶æ®µ bandwidth_logits åŒ…å« NaN æˆ– Inf å€¼ï¼Œä½¿ç”¨å‡åŒ€åˆ†å¸ƒ")
                    # ä¿æŒæ¢¯åº¦ä¿¡æ¯ï¼Œåªæ›¿æ¢æ— æ•ˆå€¼
                    bandwidth_logits = torch.where(torch.isnan(bandwidth_logits) | torch.isinf(bandwidth_logits), 
                                                 torch.zeros_like(bandwidth_logits), bandwidth_logits)
                
                bandwidth_probs = F.softmax(bandwidth_logits, dim=-1)
                
                bandwidth_dist = torch.distributions.Categorical(bandwidth_probs)
                current_log_prob = bandwidth_dist.log_prob(bandwidth_actions[i])
                entropy = bandwidth_dist.entropy().mean()
                
                current_log_probs.append(current_log_prob)
                entropies.append(entropy)
        
        if current_log_probs:
            # å¤„ç†ä¸åŒé•¿åº¦çš„logæ¦‚ç‡
            all_current_log_probs = []
            all_old_log_probs = []
            all_advantages = []
            all_entropies = []
            
            for i, (current_log_prob, old_log_prob, entropy) in enumerate(zip(current_log_probs, old_log_probs, entropies)):
                all_current_log_probs.append(current_log_prob)
                all_old_log_probs.append(old_log_prob)
                all_entropies.append(entropy)
                # ä¸ºæ¯ä¸ªé“¾è·¯åˆ†é…ç›¸åŒçš„ä¼˜åŠ¿å€¼
                all_advantages.extend([advantages[i]] * len(current_log_prob))
            
            # è¿æ¥æ‰€æœ‰logæ¦‚ç‡
            current_log_probs = torch.cat(all_current_log_probs)
            old_log_probs = torch.cat(all_old_log_probs)
            all_advantages = torch.tensor(all_advantages, device=self.device)
            entropies = torch.stack(all_entropies)
            
            # è®¡ç®—æ¯”ç‡
            ratio = torch.exp(current_log_probs - old_log_probs)
            
            # PPOæŸå¤±
            surr1 = ratio * all_advantages
            surr2 = torch.clamp(ratio, 1 - self.clip_ratio, 1 + self.clip_ratio) * all_advantages
            bandwidth_loss = -torch.min(surr1, surr2).mean()
            
            # ç†µæŸå¤±
            entropy_loss = -entropies.mean()
            
            # æ€»æŸå¤±
            total_loss = bandwidth_loss + self.entropy_coef * entropy_loss
            
            # æ›´æ–°
            self.bandwidth_optimizer.zero_grad()
            total_loss.backward()
            self.bandwidth_optimizer.step()
    
    def _update_critic(self, states, returns):
        """æ›´æ–°Critic"""
        values = []
        
        for state in states:
            physical_features = state['physical_features'].to(self.device)
            physical_edge_index = state['physical_edge_index'].to(self.device)
            physical_edge_attr = state['physical_edge_attr'].to(self.device)
            virtual_features = state['virtual_features'].to(self.device)
            virtual_edge_index = state['virtual_edge_index'].to(self.device)
            virtual_edge_attr = state['virtual_edge_attr'].to(self.device)
            
            value = self.critic(
                physical_features, physical_edge_index, physical_edge_attr,
                virtual_features, virtual_edge_index, virtual_edge_attr
            )
            values.append(value)
        
        values = torch.cat(values)
        returns = returns[:len(values)]
        
        # ä»·å€¼æŸå¤±
        value_loss = F.mse_loss(values, returns)
        
        # æ›´æ–°
        self.critic_optimizer.zero_grad()
        value_loss.backward()
        self.critic_optimizer.step()
    
    def _compute_advantages(self):
        """è®¡ç®—ä¼˜åŠ¿å‡½æ•°"""
        rewards = torch.tensor(self.rewards, dtype=torch.float32, device=self.device)
        values = torch.tensor(self.values, dtype=torch.float32, device=self.device)
        dones = torch.tensor(self.dones, dtype=torch.float32, device=self.device)
        
        advantages = torch.zeros_like(rewards)
        last_advantage = 0
        
        for t in reversed(range(len(rewards))):
            if t == len(rewards) - 1:
                next_value = 0
            else:
                next_value = values[t + 1]
            
            delta = rewards[t] + self.gamma * next_value * (1 - dones[t]) - values[t]
            advantages[t] = delta + self.gamma * self.gae_lambda * (1 - dones[t]) * last_advantage
            last_advantage = advantages[t]
        
        return advantages

def test_two_stage_actor():
    """æµ‹è¯•ä¸¤é˜¶æ®µActoræ¶æ„"""
    print("ğŸ§ª æµ‹è¯•ä¸¤é˜¶æ®µActoræ¶æ„")
    print("=" * 60)
    
    # æµ‹è¯•å‚æ•°
    physical_node_dim = 4
    virtual_node_dim = 2  # ä¿®æ”¹ï¼šä»3æ”¹ä¸º2ï¼ˆåˆ é™¤ä¼˜å…ˆçº§ç‰¹å¾ï¼‰
    num_physical_nodes = 5
    max_virtual_nodes = 4
    bandwidth_levels = 10
    
    # åˆ›å»ºæ™ºèƒ½ä½“
    agent = TwoStagePPOAgent(
        physical_node_dim=physical_node_dim,
        virtual_node_dim=virtual_node_dim,
        num_physical_nodes=num_physical_nodes,
        max_virtual_nodes=max_virtual_nodes,
        bandwidth_levels=bandwidth_levels
    )
    
    print(f"âœ… æ™ºèƒ½ä½“åˆ›å»ºæˆåŠŸ")
    print(f"   æ˜ å°„Actor: {sum(p.numel() for p in agent.mapping_actor.parameters()):,} å‚æ•°")
    print(f"   å¸¦å®½Actor: {sum(p.numel() for p in agent.bandwidth_actor.parameters()):,} å‚æ•°")
    print(f"   Critic: {sum(p.numel() for p in agent.critic.parameters()):,} å‚æ•°")
    
    # åˆ›å»ºæµ‹è¯•çŠ¶æ€
    state = {
        'physical_features': torch.randn(num_physical_nodes, physical_node_dim),
        'physical_edge_index': torch.randint(0, num_physical_nodes, (2, 10)),
        'physical_edge_attr': torch.randn(10, 2),
        'virtual_features': torch.randn(max_virtual_nodes, virtual_node_dim),
        'virtual_edge_index': torch.randint(0, max_virtual_nodes, (2, 6)),
        'virtual_edge_attr': torch.randn(6, 2)
    }
    
    # æµ‹è¯•åŠ¨ä½œé€‰æ‹©
    mapping_action, bandwidth_action, mapping_log_prob, bandwidth_log_prob, value, link_indices = agent.select_actions(state)
    
    print(f"\nğŸ“Š åŠ¨ä½œé€‰æ‹©æµ‹è¯•:")
    print(f"   æ˜ å°„åŠ¨ä½œ: {mapping_action}")
    print(f"   å¸¦å®½åŠ¨ä½œ: {bandwidth_action}")
    print(f"   æ˜ å°„logæ¦‚ç‡: {mapping_log_prob}")
    print(f"   å¸¦å®½logæ¦‚ç‡: {bandwidth_log_prob}")
    print(f"   çŠ¶æ€ä»·å€¼: {value:.4f}")
    print(f"   é“¾è·¯ç´¢å¼•: {link_indices}")
    
    # æµ‹è¯•ç»éªŒå­˜å‚¨
    agent.store_transition(state, mapping_action, bandwidth_action, 1.0, value, mapping_log_prob, bandwidth_log_prob, False)
    
    print(f"\nâœ… ç»éªŒå­˜å‚¨æµ‹è¯•æˆåŠŸ")
    print(f"   ç¼“å†²åŒºå¤§å°: {len(agent.states)}")
    
    # æµ‹è¯•ç½‘ç»œæ›´æ–°
    agent.update()
    
    print(f"\nâœ… ç½‘ç»œæ›´æ–°æµ‹è¯•æˆåŠŸ")
    print(f"   ç¼“å†²åŒºå·²æ¸…ç©º: {len(agent.states) == 0}")
    
    print(f"\nğŸ¯ ä¸¤é˜¶æ®µActoræ¶æ„æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    test_two_stage_actor() 